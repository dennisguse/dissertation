\chapter{State-of-the-art of Multi-episodic Perceived Quality}\label{chap:05}
\begin{chapter-abstract}
%NOTE: This chapter might be too small, consider merging with previous chapter.
Here I present the state-of-the-art on multi-episodic QoE\cite{moller_single-call_2011}, \cite{duncanson_average_1969}, \cite{guse_macro-temporal_2013}.
It is important to state again the research question (How do subjects integrate low episodic quality into an overall experience?) for this domain and introduce methodologies.
Major point here is the research method (task-driven, defined usage behavior, limited freedom in usage behavior).
At the end of this chapter I must have made clear what methodologies are used and also made clear what their respective target is.
\end{chapter-abstract}

%TODO Add sentence about multiple service / bundles! und das das sprachlich schwierig ist!
\section{Introduction}
%Multi-episodic == Repeated use and repeated experience
Services are in general used on a regular basis by a user.
The experiences of a usage episode lead to a perceived quality in the user of this very episode. %NOTE Influence factors (human etc.)
The multi-episodic perceived quality is the result of an \emph{integrating process} combining prior experiences and perceived qualities with said service.
Prior experiences can affect the \emph{quality formation process} of a user and such a change affects the perceived quality of following usage episodes.
%Also a re-evaluation of the perceived quality of prior episodes might occur.
%Quality formation process: Reflection and Attribution, Comparison & Judgment, Encoding
The user's behavior towards the service might also be affected by the perceived quality like usage frequency, task solving strategies, or even abandon the service completely.
Multi-episodic perceived quality must be thus regarded as a sequential process in which the experienced order of usage episodes affect the outcome. %NOTE: Is sequential process correct?
Investigations on multi-episodic perceived quality can therefore only be undertaken in experiments adhering to a between-subject design, so that every subject is only exposed to one condition.

In the field of perceived quality multi-episodic perceived quality has so far only received limited attention.
One reason for this is that research in the field of perceived quality is technology-driven.
This means that the major focus lies on the evaluation of new technologies, understanding of potential impairments, and the impact on perceived quality.
The derived knowledge is then applied to enhance existing technologies.
For applicability it is often sufficient to know the relationship between different performance parameters and the general effect on perceived quality, and neglect the influence of time, tasks and other factors on perceived quality.

\subsection{Excurse: Multi-episodic usage in \acl{UX}}
Multi-episodic evaluation has been done so far for the evaluation of \acf{UX}.
Perceived quality and \ac{UX} conceptually overlap as both focus on experience in general and, in many cases, experience with technology \citep[cf.][]{book chap 3}.
\ac{UX}, steaming from usability, focuses on the interaction with technology and how interactions affect usage, behavior, and emotions towards used technology.\footnote{For a longer discussion on similarities and difference between \ac{QoE} and \ac{UX} see \cite{book chapter 3} and also \cite{Hasenzahl 2008: towards user experience}.}
As interaction behavior towards technology often changes as a user learns how to use it and which tasks are well-suited, makes multi-episodic evaluation an important aspect for \ac{UX}.
The multi-episodic terminology is described by \citet[p. 8]{roto_user_2011}, but missed to put it into context with prior work and do not present their definitions.

\cite{karapanos_user_2009} investigated in an experiment with \unit[6]{subjects} how expectations and usage changes from before buying a smart phone and after an overall usage period of \unit[4]{weeks}. %RESULT?
This is extended by \cite{kujala_ux_2011} with the newly presented \emph{UX Curve Method}.
In this method a participant evaluates his experiences with a product or service in retrospective.
The participant draws a line reflecting how is satisfaction changed over time and annotates the vertices with the reason for th change.
In the reported experiment participated 20 subjects evaluating also changes in their satisfaction with their mobile phone.
Both experiments showed that the usage and also emotions towards the product under investigation changes over time.
In the beginning interaction is more playful and exploratory whereas it task-oriented and productive.


%\subsection{Excurse: BWL} Optional


\subsection{Duncanson: Average Perceived Quality}
First work in direction on multi-episodic perceived quality was performed by \cite{duncanson_average_1969} for telecommunication services.
Duncanson asked regular users of an oversea speech telephone service about the their experience with said service.
He investigated, if their is a difference between \emph{a)} the \emph{perceived quality of a just finished call} with average performance and \emph{b)} the \emph{assumed quality} of a call with average performance.
For this experiment Duncanson used a 4-point \ac{ACR} scale\footnote{\cite{duncanson_average_1969} applied a 4-point \ac{ACR} scale with the labels excellent (4), good (3), fair (2), and poor (1).} and \emph{Thurstone's Law of Categorical Judment} and found in three experiments similar results.
It could be shown that case a) is yields a higher \ac{MOS} than case b).
Duncansons concludes ``that ratings of single, recent telephone calls
yield results different from ratings of subjectively averaged, past
telephone calls of the same type'' \citep[][p. 116]{duncanson_average_1969}.

Although Duncanson studied episodic perceived quality and assumed quality of an \emph{average usage episode}, it revealed an important aspect of multi-episodic perceived quality.
It is indicated that the integration process of episodic perceived quality leads to a worse perceived quality and thus assumed quality judgment as the integration process does not equally weight all prior experiences with said service.
%Reasons: IMPORTANCE? %Peak?

\section{Assessment of Multi-episodic Perceived Quality}
Prior work in direction of multi-episodic evaluation focuses on use, experience and perception of a service or product under realistic conditions.
This is especially true for \ac{UX} as work in this area focuses on changes in behavior and emotions towards the system under investigation.

%ASSUME: MOS = average quality perception; ASSUMPTION: average quality perception over time!
Investigating perceived quality for short stimuli as well as complete usage episodes is investigated by in general exposing multiple participants to same stimulus and assess the resulting quality perceptions \citep[cf.][p. 11]{blauert_spatial_1996}. %MOELLER? JEKOSCH?
The calculation of the \ac{MOS}, independent of the type of judgment or scale, results in an\emph{average perceived quality}.
The \ac{MOS} is in general assumed to reflect the perceived quality judgment of \emph{the average participant}.

\subsection{Aspects}
With regard to multi-episodic perceived quality and, perceived quality over time in general, it is required that only those judgments can be subjected to \ac{MOS} that result from similar a condition.
For multi-episodic perceived quality the following factors are a minimal baseline that must be fulfilled, so the judgments can be evaluated with the \ac{MOS}.
This implicitly states the assumption that effects over time are of judgments for the same condition for multiple participants are comparable.
In experiments on perceived quality this \emph{temporal assumption} can in general be neglected as time frames under investigation are small in enough, \ie in the range of seconds up to some minutes.
For multi-episodic perceived quality it must be taken into account as potential factor for noise in a \ac{MOS} evaluation. %considered as factor? its not really noise, or?

Following factors are discussed that can affect multi-episodic perceived quality and thus should be kept constant, if a \ac{MOS} evaluation is applied.

\subsubsection*{Prior Knowledge and Expectations}
Perceived quality is influenced by prior knowledge about a service under consideration (cf. \autoref{chap:02}).
Prior knowledges includes knowledge about the specific service and also about the type of service in general.
For telecommunication services this includes knowledge and likely origins about service-specific degradations.
Also promises about performance by a service provider as for example provided in advertisement is considered knowledge.
Both might change expectations, attribution of degradations, and \emph{assumed quality} and thus can affect multi-episodic perceived quality.
%TODO Advertisement-Paper too good to be bad? (oder so)
This is for example expressed in the \emph{E-Model} by the \emph{advantage factor \textbf{A}} \citep{itu-t_g.107:_2014}.

\subsubsection*{Task, Task Importance and Task Solving Strategies}
The \emph{quality formation process} is also affected by the user's behavior.
This includes human factors like attention, but also to be fulfilled needs and to be solved task.
By repeated use the user's behavior might adjust, if certain degradations are encountered, so that task solving is effective and efficient.
Depending on the actual tasks, degradations might even not be noticeable like high delay in telephone conversation with rare turn-taking \citep[cf.][]{schoenenberg_quality_????}. %TODO Better ref.
In fact, a degradation might also enforce a change in task solving strategy, \eg reduced turn-taking due to high delay telephone conversation \citep[cf.][]{schoenenberg_quality_????}.
As the evaluation of multi-episodic perceived quality relies on a retrospective judgment, factors that influence the likelihood to recall a specific usage episode are considered important.
This also includes the importance of a task, task duration and its fulfillment for a user.
For example an interviewee in a telephone job interview is likely to recall this specific usage episode and describe his perceived quality compared to call with a friend.

Therefore the task, task solving strategies and also importance of a specific usage episode should be understood to assess its impact on the assessment of multi-episodic perceived quality.

\subsubsection*{Usage Pattern}
Multi-episodic perceived quality can be affected by usage pattern.
The usage pattern describes when a service is used.
A usage pattern can be regular with a defined frequency, and also irregular with bursts of usage.
The usage pattern, in fact, describes how often a user is exposed to the service's performance and thus acquire new information about the multi-episodic perceived quality.
For the investigation of multi-episodic perceived quality, it is therefore required that usage pattern are similar.

\subsection{Assessment Methodology: Free-use}
Multi-episodic perceived quality can be assessed by observing user's interaction with a service without restricting their usage behavior.
This approach has for example been taken \cite{duncanson_average_1969}.
Here user's are free to select when and how to use a service, to abandon it, and also acquire new information about it. %e.g. adverstisements
Often information about per user usage pattern, service performance, tasks, goals, expectations, prior knowledge, and also personality cannot be acquired.
This lack of information is often overcome by sampling a large amount of users to overcome.
Another option to reduce the impact of this lack is to gather self-reported measures of users, or gather behavioral data (\eg, churn, likelihood to re-buy, monetization).

Allowing user to decide themselves when and under which conditions a service is used, enables to investigate usage under "real conditions"\footnote{"Real conditions" means that the object under study is observed while interacting with his \emph{real} environment, which changes as well as the user. In fact, the term "real" does not describe precisely the actual condition, but is an imprecise umbrella term.}, \ie, how a user would behave in his current environment.

\subsection{Assessment Methodology: Defined-use}
Limiting the users freedom by defining how to interact with a service, allows to apply a \ac{MOS} evaluation.
For multi-episodic perceived quality this requires to define the usage pattern for the service, and for each usage episode the task and service performance.
This enforces that all users are exposed in a similar manner to the service.
A task can be artificial, \ie, a user must not necessarily engage in such a task on his own, and should lead to a similar task solving strategy.
For telecommunication services this could be a telephone call with defined content \citep[cf.][]{itu-t_p.805:_2007}, or even listening to a recorded telephone call.

To limit an influence of prior experiences and information about a service, it must made sure that users have a similar knowledge and exposure with the service.
This can be achieved by a careful selection of users, or by creating a \emph{new service}.
Creating a new service does not prevent that a user has prior knowledge about such a type of service, but avoids that prior experiences, especially with regard to perceived quality, affect the multi-episodic perceived quality.

\subsection{Discussion}
Both assessment methodologies are diametrically opposed. Free-use allows studying multi-episodic perceived quality with existing user by observing their interaction with said service and optionally gather direct feedback, but is limited This non-intrusive methodology is, however, in general limited by information that can be gathered about a user.
In addition, service performance cannot be controlled and desired performance might occur not reliably enough.
Modifying the service performance on purpose, however, introduces ethical issues, if users are not informed about this and the underlying reason.
The latter, actually, influences the quality formation process by setting expectations and thus affect multi-episodic perceived quality judgments.

Defined-use, on the other hand, requires a large effort as a new service must be created.
The deployed service be able to provide \emph{defined service performance} precise and reliable.
This means that such a service must be able to introduce degradations, when defined, and prevent degradations, when none are defined, from a end-to-end perspective and on a per user basis.
This is challenging task for telecommunication services especially due to the necessary data transmission and non-desired transmission-related degradations that often cannot be controlled in a reliable manner.
In addition to technological challenges to deploy such a service, a user needs to solve artificial tasks at specific point in time.
This is not problematic if multi-episodic perceived quality is studied in one session, \eg several consecutive telephone calls.
Investigating multi-episodic perceived quality over larger time-spans covering several days, weeks, or months, however, increases the required to effort for a user.
This increases the need for compensation, which if served in monetary terms is costly.
However, investigating multi-episodic perceived quality beyond one session alone enables to derive how usage episodes are recalled and perceived quality potentially forgotten.
However, larger time-spans also increase the likelihood that a defined usage pattern cannot be fulfilled by a user as each user must embedded service usage into their daily life.

\section{Initial work on Multi-episodic Perceived Quality}
%Constant performance!

%Moeller2011 developed and a applied a research methodology for multi-episodic QoE, but results were limited: low performance episode did not statistically affect multi-episodic QoE.

%Works in general, but fails sometimes (negative peaks)
\cite{moller_single-call_2011}: First conducted multi-episodic QoE study.
%Major Result: methodology can be applied, episodic quality judgments show that performance could be provided with the used system.
%Minor Results: 
%increase of episodic QoE judgments over time? (significant)
%\item conditions did not yield significant different multi-episodic QoE, but at least consistent

%TODO Critize study as the performance cannot be replicated, no recordings, system description, performance monitoring
%Limitation: no "training" and no supervised usage(?) 
%NO imposter detection!, very expansive