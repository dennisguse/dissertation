\addtocontents{toc}{\protect\newpage}
\chapter{Experiments: One Session}\label{chap:lab}
\begin{chapter-abstract}
First question: can multi-episodic QoE be studied in "short" laboratory study?
I with my laboratory studies on with one speech telephony service focusing on effects of position(s) of degraded usage episodes (the finished Journal paper) and the already finished extensions.
\end{chapter-abstract}

For the evaluation of the six hypotheses with regard to multi-episodic perceived quality for sequential use in one session four experiments were conducted.
These experiments follow the same procedure, but differ in usage situation and, respectively, service type as shown in \autoref{tab:lab:experiments}.

%Overview on Experiments
\begin{table}[h]
	\begin{tabulary}{\textwidth}{C|C|C|C|C}
	Experiment	& Service Type 				& Task								& Episodes & Hypothesis \\
	\hline
	E1			& Telephony					& Two-party conversation (\ac{SCT})	& 6-9      & H1, H2, H3, H5 \\
	\hline
	E2a			& Telephony					& 3rd-party listening (\ac{SCT})		& 6        & H1, H2 \\
	\hline
	E2b			& Telephony and \ac{VoD}	& E2a with Movie							& 12       & H6\\
	\hline
	E3			& \ac{AoD}					& Audiobook													& 6        & H4\\
	\end{tabulary}
	\caption{Overview on conducted experiments for multi-episodic perceived quality in one session.}
	\label{tab:lab:experiments}
\end{table}

In the following, first the experimental design that is shared between the four conducted experiments is presented, followed by an overview on the applied conditions to investigate the hypotheses.

\section{Design}
For the investigation of multi-episodic perceived quality in one session service types and usage situations were selected that are based upon audio, \ie, mainly speech.
Using a unimodal rather than a multi-modal service avoids that the integration process of individual modalities into an \emph{overall perceived quality} must be considered and thus eliminates one potential influencing factor.
Varying the service type as well as usage situation, it is not yet known, how if those affect multi-episodic perceived quality.

All experiments consisted of at least 6 usage episodes.
Each usage episode should lead to a minimal usage duration of \unit[2]{min}.
This is, in fact, only an issue for experiment E1 due to the fact that in this experiment, the user behavior affects the duration of an episode, which is not the case in the other three experiments.

For all experiments the first three episodes were always presented with the highest service performance (\ie, \acf{HP}).
This enables participants could experience the service in a well-working setting \citep[\cf,][]{moller_single-call_2011}.
Non-\ac{HP} were only introduced per service for episode 4, 5, and 6.

In all experiments a multi-episodic judgment on the 7-point \ac{CCR} is taken after finishing every third episode.

\subsection{Conditions}
Overall 10 conditions were created that allow to investigate the six hypotheses in detail (\cf, \autoref{chap:towards}).
All conditions are shown in \autoref{tab:lab:hypothesesComparison}.
Differences between conditions can be evaluated by comparing multi-episodic judgments that were taken after the same usage episode, \ie participants experienced the same number of usage episodes so far.

%TODO Abkuerzung aller Conditions C1-C7?

\begin{table}[h]
 \centering
 \begin{tabulary}{\textwidth}{C|C||C|C|C||C||}
 Condition & \multicolumn{5}{c|}{Episodic Performance}        \\
           & 1-3	& 4           & 5           & 6           & 7-9 \\
 \midrule
 C0		   & HP		& HP		  & HP			& HP		  & - \\
 \hline
 C1         & HP 	& \textbf{LP} & HP          & HP          & - \\
 \hline
 C2a        & HP 	& HP          & \textbf{LP} & HP          & - \\
 \hline
 C2b        & HP 	& HP          & \textbf{LP}, long & HP    & - \\
 \hline
 C3         & HP 	& HP          & HP          & \textbf{LP} & - \\
 \hline
 C4         & HP 	& \textbf{LP} & \textbf{LP} & HP          & - \\
 \hline
 C5a        & HP 	& HP          & \textbf{LP} & \textbf{LP} & - \\
 \hline
 C5b        & HP 	& HP          & \textbf{LP} & \textbf{LP} & HP \\
 \hline
 C6         & HP 	& \textbf{LP} & \textbf{LP} & \textbf{LP} & - \\
 \hline
 C7         & HP 	& HP          & \textbf{LP} & \textit{MP} & HP \\
 \hline
 C8         & HP 	& \textbf{LP} & HP          & \textbf{LP} & - \\
 \end{tabulary}
 \caption{Overview of all conditions with the episodic performance of all usages episodes.
 Non-HP episodes are in \textbf{bold} (\ac{LP}) and \textit{italic} (\ac{MP}).}
 \label{tab:lab:hypothesesComparison}
\end{table}

H1, \ie, increasing the number of \ac{LP} episodes reduces the following multi-episodic judgment, can be investigated by comparing the results of conditions 3, 5 (a+b) and 6 as well as conditions 2a and 4.
The former presents an increasing number of \ac{LP} episodes directly before the multi-episodic judgment whereas the latter presents the last episode before the multi-episodic judgment in \ac{HP}.

H2 focuses on the position of the \ac{LP} episodes towards the following multi-episodic judgment.
Following the so-called recency effect, it is expected that increasing the number of \ac{HP} episodes before the multi-episodic judgment reduces the negative effect of presented \ac{LP} episodes.
This can be investigated by comparing the multi-episodic judgment of conditions 1, 2, and 3 as well as conditions 4 and 5 (a+b) for one and, respectively, two LP usage episodes.

H3 is similar to H2 as the position of \ac{LP} episodes towards the final multi-episodic judgment is varied, but focuses on recovery between two consecutive multi-episodic judgments due to presentation of additional \ac{HP} episodes.
This can be evaluated by comparing the results of conditions 5b and 7, which are both extended by an additional block of three \ac{HP} episodes.

H4 focuses on the impact of duration of one \ac{LP} episode on a following multi-episodic judgment by expecting a higher reduction, if a longer \ac{LP} episode is presented.
This is evaluated by comparing conditions 2a versus 2b, which both provide the 5th usage episode in \ac{LP} but with a different length.
Whereas episodes of condition 2a are presented in a similar length, the \ac{LP} episode in condition 2b is doubled in duration compared.
Presenting the \ac{LP} episode as the 5th episode followed by one \ac{HP} episode is chosen, so that participants are suggested the difference in duration.
Doubling the duration should enforce a measurable effect, if duration is not neglected.
In fact, condition 5b is similar to condition 4 as both present the same overall duration of \ac{LP}, which is split in condition 4 into two episodes, followed by one \ac{HP} episode before the multi-episodic judgment.

H5 focuses on a potential existing peak-effect, \ie a multi-episodic judgment is larger affected by the lowest episodic performance. 
Such an effect has been observed in the retrospective assessment of general experiences, but also for retrospective assessment of episodic perceived quality.
This is investigated by presenting in addition to \ac{HP} and \ac{LP} a third performance level \ac{MP}, which provides a performance between \ac{HP} and \ac{LP}.
H5 can be investigated by comparing condition 7, which presents the 5th episode in \ac{LP} and the 6th episode in \ac{MP}, with condition 5 (a+b) and condition 2a with regard to the multi-episodic judgment after the 6th usage episode.
Those three condition differ only in the performance of the 6th episode presenting it in \ac{HP}, \ac{MP}, and \ac{LP}.
If a peak-effect occurs in the formation process of multi-episodic perceived quality, the result of condition 7 should not differ from the result of condition 2a.

H6 it is hypothesized that multi-episodic perceived quality is judged on a per-service basis, \ie, usage of different, distinct service types in the same usage period does not affect each others multi-episodic judgment.
Following the experimental approach of sequential usage episodes this can be investigated by presenting a second service in the same usage period, where both services are used sequentially.
This is investigated for two overall conditions presenting the first service always in condition 4, \ie the 5th and 6th usage episodes is presented in \ac{LP}.
The 2nd service is presented in two conditions to investigate, if the condition of the 2nd service affect the judgment of the first service.
The second service is presented in condition 8, \ie, all episodes in \ac{HP}, as well as condition 4.

%Describe each used service and usage situation (mobile vs. PC vs. [optional] living room)
%Describe tasks per service and requirements

\subsection{Performance Levels}
In each of the four experiments a speech-only service was used.
By using similar manifestations for the performance levels, the multi-episodic judgments for the same conditions between different experiments can be compared and thus draw conclusion about potential impact of the usage situation as well as service type on the results.

Three performance levels (\ac{HP}, \ac{MP}, and \ac{LP}) must be selected in a way that episodic judgments decrease, and that \ac{LP} is very likely to produce a measurable effect on multi-episodic judgments.
Thus, the \ac{LP} should be not only noticeable but rather present a \emph{severe} reduction in performance. 
However, it must ensured that solving a task is not prevented, if \ac{MP} or \ac{LP} are applied.
All performance level should lead to \emph{constant} impairments rather than fluctuations in one episode over time.
This can be achieved for digital transmission systems in the encoding and compression stage, \eg, selection and configuration of the codec.
Introducing degradations by coding and compression alone enables to apply those performance levels to listening-only as well as a conversational usage situation.

%TODO! BE CAREFUL with MOS here!
\ac{HP} can be properly chosen by selecting a current configuration that provides state-of-the-art performance level.
For speech telephony this is at the time of this writing the transmission in wideband with proper loudness, but without loss, noise, echo, reverberation or other negative factors.
For digital transmission of wideband speech the codec \emph{G.722} with Mode 1 (\unit[64]{kbit/s})~\cite{itu-t_g.722} is often used reference condition as it achieves very similar quality judgments like pure wideband filtered speech signals. %TODO Add refs, Moeller, Raake, Marcel
%Furthermore, this codec is although it is rather old, but still in active use.
In subjective experiments G.722 with Mode 1 typically achieves a \ac{MOSLQ} around 4.5 on 5-point \ac{ACR} scale.

For \ac{LP} the speech signal the \emph{LPC-10}\footnote{LPC-10 is also known as \emph{FS-1015} as well as \emph{STANAG 4198}.} codec is selected. %TODO REF
This codec is designed for low bitrate radio transmission focusing on intelligibility rather than naturalness.
The re-synthesized speech sounds very unnatural and is often described as robotic, and muddy with a hissing background noise by providing only narrowband transmission.
LPC-10 achieves a 5-point $\ac{MOS}_LQ$ of 2.3~\cite{gibson book}.
In fact, LPC-10 is not designed for speech telephony especially due to the focus on a low bitrate of \unit[2.4]{kbit/s}.
However, available codecs that are designed for speech telephony achieve rather high \ac{MOS} scores.
Even the worst codec, \ie, \ac{MELP}, only results in a 5-point \ac{MOS} of 3.0. 
LPC-10 is therefore useful for the investigation of multi-episodic perceived quality for speech-based services, because it allows to create severe degradations alone and is thus likely to affect the formation process multi-episodic perceived quality.

For \ac{MP} \emph{G.711}~\cite{itu-t_g.711} is selected, because this is the common reference condition for narrowband speech telephony.
Compared to G.722 on a 5-point $\ac{MOS}_LQ$ of is achieved due to the lower speech bandwidth.
However, in comparison to LPC-10 the re-synthesized speech signal contains far less artifacts.

As LPC-10 is rarely evaluated with compared to G.711 as well as G.722 an objective evaluation using \ac{POLQA}has been conducted.
\ac{POLQA} estimates the \ac{MOS} for the 5-point \ac{ACR} scale, which is based upon the listening-only experiments for stimuli of a duration \unit[8...12]{sec}.
\cite{koster_comparison_2015} created a transformation function that allows to transform judgments from the 5-point \ac{ACR} scale to the 7-point \ac{CCR} scale and vice versa.
The evaluation has been conducted with \unit[12]{sec} long German speech samples with \ac{POLQA} in super-wideband mode and the resutls transformed to the 7-point \ac{CCR} scale.
The results are shown in \autoref{tab:lab:performance}.

\begin{table}[h]
 \centering
 \begin{tabulary}{\columnwidth}{C|C|C|C}
   Performance & Signal bandwidth & Codec & $MOS_{LQO}$ \\
   \midrule
   \ac{HP} & 50...\unit[7000]{Hz}  & G.722, Mode 1 & 4.0 \\ %MOS1-5: 3.9
   \hline
   \ac{MP} & 300...\unit[3400]{Hz} & G.711         & 3.3 \\ %MOS1-5: 3.3
   \hline
   \ac{LP} & 300...\unit[3400]{Hz} & LPC-10        & 1.9 \\ %MOS1-5: 2.0
   \end{tabulary}
   \caption{Details of performance levels (\ac{HP}, \ac{MP}, and \ac{LP}) with \ac{POLQA} prediction (Mode: Super-wideband).
   The prediction was transformed on the 7-point \ac{CCR} scale shown in  \autoref{img:chap05:quality-scale} by applying the transformation described in \cite{koster_comparison_2015}.}
   \label{tab:lab:performance}
\end{table}

For a two-party conversation the end-to-end delay is an additional factor influencing perceived quality.
Providing a proper one-way delay up to \unit[100]{ms} is rarely noticeable and is not perceived as degradation~\citep[\cf,][p. 9]{itu-t_g.107:_2005}.
LPC-10 requires a look-ahead of \unit[90]{ms} while a frame size of \unit[22.5]{ms} is applied resulting in an delay of up to \unit[112.5]{ms} for encoding alone.
G.711 and G.722 provide a algorithmic delay without look-ahead of \unit[0.125]{ms} and, respectively, XXXX while both codecs can be run with minimal frame size of \unit[10]{ms}. %TODO 
Thus LPC-10 alone might introduce additional noticeable difference due to the additional introduced delay.

For the \ac{VoD} service a \emph{Nexus 7 (2012)} was used.
This device has a \unit[7]{inch} screen with a resolution of $1280x800$.
For \ac{HP} video content is downscaled to this resolution\footnote{The Nexus 7 is not capable of playback of raw video signals and thus the video signal is downscaled and re-encoded with H.264, \unit[25]{\ac{FPS}}, \unit[5]{mbit/s}, two-pass coding resulting in no visible additional distortions.} and audio mixed to two channels encoded with \ac{AAC} with \unit[48]{kHz}.
For \ac{LP} the video signal only is degraded encoding it in H.264 with the same resolution, and frame rate but defined \ac{QP}.
Setting a higher \ac{QP} increases the blockiness of a frame as less information is encoded.
In difference to limiting the bandwidth, \ac{QP} results in a near constant degradation over multiple frames.  %TODO REF
Degrading the video channel of the \ac{VoD} service only is chosen over degrading the audio or both channels, because then the \ac{VoD} service and \ac{AoD} service are not degraded in the same modality.
Thus a direct comparison of the presented degradations between the two services is not possible.

In all experiments a binaural representation is provided using a pair of headphones and, if needed, audio capturing using a headset.
The experimental setups are described in \autoref{chap:appendix} in \autoref{appendix:laboratorySetups}.

\subsection{Procedure} % Design
The experiments consists of 5 stages with an overall duration of from \unit[45...90]{min}.
In the \emph{first stage} a participant was informed about this experiment, his task(s), and the experimental procedure, and demographic data collected.
In this stage also participant filled a questionnaire with demographic and signed a consent form.
%E1: Telefonpartner bekannt

In the second stage participant were checked for hearing impairments using an audiometer for the frequency \unit[125]{kHz}, \unit[250]{kHz}, \unit[500]{kHz}, \unit[1000]{kHz}, \unit[2000]{kHz}, \unit[4000]{kHz}, and \unit[8000]{kHz} covering the spectrum for wideband.
This procedure was conducted with \emph{Ear 1.7} audiometer connected to a pair of \emph{Sennheiser HDA 200}.

In the \emph{third stage} participants conducted a training.
Presenting a training showing a range of potential degradations is expect to reduce intra-personal variations.
In all experiments participants rated 27 speech stimuli with a duration of circa \unit[8]{sec} with two male and one female speaker.
Those stimuli contained different bandwidth (wideband, narrowband), codecs (G.711, G.722, GSM-FR, LPC-10), white noise without codec, and random packet-loss with G.722 no \ac{PLC} (with 2\%, and 5\%).
In E2b an additional training was included for the \ac{VoD} service.
Here, 22 videos with an approximate duration of \unit[8]{sec} were used.
As degradations only the \ac{QP} was varied (0, 42, 47, and 50) while audio was left unchanged.
After the presentation of a stimulus the \emph{overall perceived quality} needed to be judged on the 7-point \ac{CCR} scale.\footnote{The question was phrased in German: "Wie bewerten Sie die Gesamtqualität der gehörten Audioaufnahme?" for speech-based training and "Wie bewerten Sie die Gesamtqualität des gerade gesehenen Videos?" in case of the video training.}

In the \emph{fourth stage} the multi-episodic part was conducted consisting of sequential use of said service(s).
In all four experiments the participants judged directly after finishing an episode their episodic quality on the 7-point \ac{CCR} scale.
In addition, could describe the experienced degradation in quantitative form.
A multi-episodic judgment is taken after every three episodes on the 7-point \ac{CCR} scale.
In this stage 6 to 12 episodes were presented.
In E2a, E2b, and E3 pre-processed content was presented varying from \unit[2]{min} to \unit[3]{min} in duration.
In E1 the duration was not controlled as the \acs{SCT} needed to be fulfilled in a two-party conversation resulting in varying duration.

In the \emph{fifth stage} final feedback about the fourth stage is collected.
In all experiments the underlying question of the \ac{NPS} is collected.
The \ac{NPS} has been proposed as the one sufficient question indicating business success~\citep[\cf,][]{reichheld_one_2003}.
This score assessed on 11-point discrete scale ranging from 0 to 10 and is phrased as "How likely is it that you would recommend our company/product/service to a friend or colleague?"~\citep[][p. 5]{reichheld_one_2003}.
In this study it was rephrased to "On scale ranging from 0 (unlikely) to 10 (likely), how likely is it that you would recommend the service to a friend or colleague?"\footnote{The question was phrased in German: "Auf einer Skala von 0 (unwahrscheinlich) bis 10 (wahrscheinlich), wie wahrscheinlich ist es, dass Sie das System einem Freund oder Kollegen weiterempfehlen werden?".}.
In E1, E2a, E2b, and E3 requested to answer the following questions, if degradations have been perceived.
First the total count of degraded episodes needed to be answered, followed by request to denote the exact episodes with degradations.
It was furthermore asked, if degradations were temporary in degraded episodes. 
In E3 those three questions were asked separate for the speech service and \ac{VoD} service.
Those questions can be used as integrity check for participants.
%Telefonie (Papier; PEAK: digital);- Anzahl gestoerter Telefonate (Freitext vs. 0-9)
%- Welche (Freitext vs. 0-9)?
%- Dauer der Stoerung (Ja/Nein)

In E3 different questions were asked in the fifth stage due to the focus on duration neglect.
Here it was assessed in a quantitative form, if episodes were degraded and if so, which one.
In addition, it was asked, if all episodes were similar in length, and how long one episode was.

\subsection{Content}
In experiment E1 six to nine \acs{SCT}, depending on the condition, were used as defined in \cite{itu-t_p.805:_2007}.
For all conditions in this experiment the presentation order of the \acs{SCT} was kept constant.
In difference to \cite{itu-t_p.805:_2007} no \ac{SCT} needed to be solved beforehand, but participants were given a written and oral explanation using an exemplary \ac{SCT}.
The actual order of the \acs{SCT} is given in \autoref{} \autoref{tab:appendix:labsct}.

In E1 the two-party conversations were recorded before applying the performance level for each speaker channel individually with a sampling rate of \unit[16]{kHz}.
One recording for each episode 1 to 6 of those that have been presented in \ac{HP} was selected for experiment E2a and E2b.
The recordings common task solving behavior with several speaker changes and only with little double talk.
Furthermore, no emotional reaction like laughing should be present and not contain any degradations due to other sound sources like breathing sounds, but only clear and clean speech.
Male and female speakers were selected.
The selected recordings had an average duration of \unit[153]{sec} ranging from \unit[128]{sec} to \unit[194]{sec}.
The individual speech signals of each speaker were normalized, mixed into one channel and then encoded with G.722 or, respectively, LPC-10.
The six selected recordings were presented in E2a and E2b in the same order as in E1.

For the \ac{VoD} service that was to be simulated in E2b, scences from one sitcom were taken.
Here scenes were taken from \emph{The Big Bang Theory} (Season One, BluRay Version, German).
Those scenes were selected in a way that the duration of the two-party conversational recordings were closely matched.
Furthermore, scenes needed to be itself meaningful as well as self-contained and are likely candidates for usage episode, \ie, such a scene would be watched out of context.
The episodes had an average duration of \unit[166]{sec} ranging from \unit[134]{sec} to \unit[198]{sec}.

For the simulation of an \ac{AoD} service in experiment E3 an audio book was selected.
Here Isabel Allende's \emph{"City of the Beats"}  was used, spoken by Marc Oliver Schulze a male German native speaker.\footnote{The audio book is sold as 24 CD collection: Isabel Allende: \emph{Die Stadt der wilden Götter / Im Reich des goldenen Drachen / Im Bann der Masken}, ISBN: 978-86717-191-5.}.
Scenes were selected according to the same criteria applied for the video content used in E2b.
The episodes had an average duration of \unit[184]{sec} ranging from \unit[174]{sec} to \unit[199]{sec}.

%In all experiments the content is completely in German.
%In case of the \ac{VoD} content the German-dubbed version was used.
%Versuchspersonenanzahl per Condition (15)?

\section{Participants}
All four experiments were conducted in Berlin, Germany.
Participants were required to have no hearing impairments for all of the four experiments.
For participation in E2b normal vision was additionally mandatory.

Experiment E1 was conducted  with \unit[59]{female} and \unit[40]{male} participants aging from 19 to \unit[53]{years} ($\mu=27.2$, $\sigma=6.5$). %TODO Ist falsch!
This experiment was conducted from April 2014 until August 2015.
Experiment E2a was conducted with \unit[65]{female} and \unit[35]{male} participants aging from of 18 to \unit[50]{years} ($\mu=26.1$, $\sigma=4.6$). %TODO Ist falsch!
This experiment was conducted from August 2014 until March 2015.
In experiment E1 participants received \unit[15]{EUR} as compensation and participation in experiments E2a, E2b, and E3 was compensated with \unit[10]{EUR}.

%TODO Add E2b and E3

In all experiments each participant was individually checked for inconsistent episodic judgments.
A participant is considered inconsistent, if more than two episodic judgments are exceeding the 1.5 $\times$ \emph{interquartile range} of the performance levels of this condition. %TODO REF
The interquartile range is, in fact, a rather conservative criteria.
However, due to the lack of ground-truth on episodic judgments in a usage multi-episodic case, participants should be only removed, if severe differences occur.
For none participants of the four experiments this criteria was met and thus none was excluded from the data analysis.

In all four experiments overall 310 participants 
\autoref{tab:lab:participants} gives an overview on participants per condition.

%%TODO Table with conditions per Study + Number of subjects
\begin{table}
	\centering
	\begin{tabular}{c|c|c|c|c}
	Conditions & \multicolumn{4}{c}{Experiments} \\
			& E1	& E2a 	& E2b 	& E3\\
	\midrule
	C0		& -		& 	-	& 	14	&  - \\
	C1		& 13	&	12	&	-	&  - \\
	C2a		& 12	&	15	&	-	&  16\\
	C2b		& -		&	-	&	-	&  20\\
	C3		& 16	&	13	&	-	&  - \\
	C4		& 18	&	15	&	12	&  - \\
	C5a		& -		&	24	&	-	&  - \\
	C5b		& 16	&	-	&	-	&  - \\
	C6		& 16	&	21	&	-	&  - \\
	C7		& 43	&	-	&	-	&  - \\
	C8		& -		&	15 &	-	&  - \\ %TODO Check E2a! for C8
	\midrule
	$\sum$ 	& 133	&	115 &	26 	& 36 \\
	\end{tabular} %TODO Add male / female, age? or put this into the appendix
	\caption{
	Overview on conditions for the experiments E1, E2a, E2b, and E3 incl. number of participants per condition.
	For E2b the conditions of the \ac{VoD} are shown whereas the telephony service was always presented in C5a for all participants.}
	\label{tab:lab:participants}
\end{table}

\section{Data Analysis}
First, episodic QoE results are inspected with regard to consistency between conditions for each experiment individually, and then potential differences between the experiments are investigated.
Second, multi-episodic QoE results are evaluated with regard to the presented hypotheses.

All results are reported as \ac{MOS} ranging from 0 to 6 (for the scale cf. Figure~\ref{img:qualityScale}).
For statistic evaluation of two unpaired samples a \emph{Wilcoxon rank-sum test} is conducted.
More than two unpaired samples are compared by conducting a \emph{Kruskal-Wallis test} and, if significant differences are found, a \emph{pairwise Wilcoxon rank-sum test with Holms' correction} as post-hoc test is conducted.
Paired samples are evaluated with a \emph{Wilcoxon signed-rank test}.
Effect sizes for significant differences are estimated with the \emph{Hodges-Lehmann estimator} and reported as $\triangle: F_{2}(x)=F_{1}(x-\triangle)$, where $F_{1}$ and $F_{2}$ denote the two distributions and $x$ their median.
%Non-parametric tests are chosen over parametric tests like Anova due to 

\subsection{Episodic Judgments} 

%Order effect (Moeller): HP following LP

%Increase (Moeller): 1 vs last

%Consistency 
HP vs. MP vs. LP

%Differences between CONDITION and USAGE SITUATION (Task?)

%TODO Add exemplary plot of (C7)
\begin{figure}
%	\includegraphics[width=1\columnwidth]{fig/e1-condition7-boxplot}
	\caption{Boxplot for episodic QoE judgments of C7 for E1.
	The 5th usage episode is presented in LP and the 6th in MP.}
	\label{img:lab:boxplotE1c7}
\end{figure}

\subsection{Multi-episodic Judgments}
In the following the results for multi-episodic QoE are evaluated.
First consistency between conditions is analyzed with regard to the multi-episodic QoE after the 3rd usage episode.
Then the results are evaluated in detail with regard to the hypotheses under investigation.

%TODO TODO TODO
For the multi-episodic QoE judgment after the 3rd usage episode no significant difference between conditions is found for neither Study~1 ($H(6)=2.5433, p=0.8636$) nor Study~2 ($H(5)=6.4111, p=0.2682$).
%With regard to this multi-episodic QoE judgment no significant difference between Study~1 ($MOS=4.2, \sigma=0.7$) and Study~2 ($MOS=4.3, \sigma=0.8$) are found ($H(1)=2.7926, p=0.0947$).
With regard to this multi-episodic QoE judgment both studies do not differ significantly ($H(1)=2.7926, p=0.0947$, Study~1: $MOS=4.2, \sigma=0.7$, Study~2: $MOS=4.3, \sigma=0.8$).
This indicates that, as long as only HP episodes are presented, neither the between-subject design nor the task affected this multi-episodic QoE judgment.

In the following, the hypotheses under investigation are analyzed for the experiments E1, E2a, E2b, and E3.

\subsubsection{H1}
\subsubsection{H2}
\subsubsection{H3}
\subsubsection{H4}
\subsubsection{H5}
\subsubsection{H6}
\subsubsection{H7}

\section{Discussion}
